{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Summary\n",
    "\n",
    "The hippocampus is important for the learning of episodic and spatial memory, but how it coordinates its activity with other memory-related brain structures is not well known. Of particular interest is the prefrontal cortex (PFC), because of its diverse roles in attention, working memory, long-term memory storage and memory-guided decision making. The goal of this project is to investigate whether neural activity is systematically coordinated between hippocampus and PFC during memory-guided decision making.\n",
    "\n",
    "Sharp wave ripples (SWR) are a prominent high-frequency hippocampal oscillation linked to memory-guided decision making that occur when an animal is immobile. During a SWR, neurons that were previously active for a particular spatial location in an environment \"replay\" their activity in a compressed sequence, as if the animal were currently moving through the environment. Interestingly, these compressed sequences of neural activity occur in both the forward and reverse direction -- that is, both following a path the animal might have taken through the environment (forward SWR) and retracing a path backwards (reverse SWR). Because these SWR events often occur at critical decision points, during the receiving of reward, or during sleep, they are thought to reflect planning of future actions based on past memories (memory recall) and/or consolidation of rewarded behaviors. Furthermore, reverse replay sequences are modulated by the rate of reward while forward replay are not (Ambrose et al. 2016), suggesting that reverse replay events are more involved in the consolidation of memories during learning whereas forward replays are more important for retrieval of past memories. If this is the case, then we might expect memory information to be transferred from PFC to hippocampus during forward replays -- because of the role of PFC in long term storage of memories -- and memory information to be transferred from hippocampus to PFC during reverse replays -- to consolidate memories during learning.\n",
    "\n",
    "![Task and Brain Areas](http://www.cell.com/cms/attachment/2080561999/2072098661/gr1.jpg)\n",
    "\n",
    "To test this hypothesis, neural activity was simultaneously recorded in PFC (pre-limbic and infralimbic) and hippocampus (CA1 and intermediate CA1) of three rats learning a W-track spatial alternation task (Figure 1a,c). In the task, the rats had to run to the opposite reward well at the end of each arm of the track (left and right arms) while returning to the center well in-between visits to each arm. We analyzed rhythmic local field potential activity occurring during sharp wave ripples in both hippocampus and PFC. \n",
    "\n",
    "## Project Goals\n",
    "\n",
    "We are interested in answering the following questions:\n",
    "\n",
    "1. Is there any evidence of increased coordination between PFC and hippocampus during SWR?\n",
    "2. Are there differences in coordination between forward and reverse SWR?\n",
    "3. Is there evidence of directional influence from CA1 to PFC corresponding to forward and reverse SWR?\n",
    "4. Does any of questions 1-3 change over learning?\n",
    "5. How consistent are the results over animals?\n",
    "\n",
    "## Results so far\n",
    "\n",
    "- We can detect ripples using the [Frank lab methods](https://github.com/edeno/Jadhav-2016-Data-Analysis/blob/develop/notebooks/2016_11_07_Ripple%20Detection.ipynb) (and [power in CA1 reflects an increase in the ripple band](https://github.com/edeno/Jadhav-2016-Data-Analysis/blob/develop/notebooks/2017_03_21_Replay_Analysis.ipynb))\n",
    "- We can decode ripples using sorted spikes ([but this didn't work well](https://github.com/edeno/Jadhav-2016-Data-Analysis/blob/develop/notebooks/2017_02_09_Sorted%20Spike%20Ripple%20Decoding.ipynb))\n",
    "- We can decode ripples using the [Xinyi's clusterless method](https://github.com/edeno/Jadhav-2016-Data-Analysis/blob/develop/notebooks/2017_03_20_Clusterless%20Ripple%20Decoding.ipynb))\n",
    "- We can compute a [large number of connectivity measures](https://github.com/edeno/Jadhav-2016-Data-Analysis/blob/develop/notebooks/2017_05_30_Test%20Spectral%20Code.ipynb) and these match the [plots from examples in papers](https://github.com/edeno/Jadhav-2016-Data-Analysis/blob/develop/notebooks/2017_06_13_Test_Spectral_On_Paper_Examples.ipynb)\n",
    "- There are [about the same number of Outbound and Inbound replay events](https://github.com/edeno/Jadhav-2016-Data-Analysis/blob/develop/notebooks/2017_03_21_Replay_Analysis.ipynb)\n",
    "- There are [more reverse replays than forward replays during learning (days 1-6)](https://github.com/edeno/Jadhav-2016-Data-Analysis/blob/develop/notebooks/2017_03_21_Replay_Analysis.ipynb).\n",
    "- There are [more forward replays when a novel environment is introduced after learning (days 7-8)](https://github.com/edeno/Jadhav-2016-Data-Analysis/blob/develop/notebooks/2017_03_21_Replay_Analysis.ipynb).\n",
    "- There is not much coherence in the gamma bands (30-125 Hz) between CA1, iCA1 and PFC\n",
    "- There is coherence in the beta band (12-30 Hz) between CA1, iCA1, and PFC, but this overlaps with the \"sharp wave\" of the sharp wave ripple and might be uninteresting.\n",
    "- There is coherence in the ripple band (150-250 Hz) between CA1, iCA1, and PFC, but this might reflect increased spiking activity in both areas and might be uninteresting.\n",
    "\n",
    "\n",
    "## Things we have not looked at\n",
    "- Computing uncertainty of connectivity measures.\n",
    "- Connectivity over entire epoch.\n",
    "- Using a different baseline when compare before ripple to after ripple (use entire session instead of -400 ms before ripple)\n",
    "- Detecting ripples using Long Tao's algorithm for better start times\n",
    "- Neuron-neuron connectivity\n",
    "- Ripple-triggered PETHs for all sessions (we looked at these for a single session. [CA1 neurons did increase firing at the start of the ripple for this single session](https://github.com/edeno/Jadhav-2016-Data-Analysis/blob/develop/notebooks/2016_10_06_Ripple%20Triggered%20PETH.ipynb)).\n",
    "- Ripple-triggered LFP ERPs for all sessions (again we looked at these for a single session. See [this notebook](https://github.com/edeno/Jadhav-2016-Data-Analysis/blob/develop/notebooks/2016_11_07_Sharp%20Wave%20Ripple%20Exploration%204.ipynb) and [this notebook](https://github.com/edeno/Jadhav-2016-Data-Analysis/blob/develop/notebooks/2016_10_06_Ripple%20Triggered%20PETH.ipynb). We did not come to any definitive conclusions.\n",
    "- Decoding ripples in PFC\n",
    "- Better replay speed estimation\n",
    "- Better model for reverse time trajectory for the ripple decoding \n",
    "\n",
    "## Work this week\n",
    "\n",
    "### Figuring out how to compute the baseline for comparison to the ripple period\n",
    "Previously I had been comparing the power or connectivity measure -400 ms before the ripple to the power or connectivity measure around the time of the ripple. I thought this was the method used in:\n",
    "\n",
    "> Carr, M.F., Karlsson, M.P., and Frank, L.M. (2012). Transient Slow Gamma Synchrony Underlies Hippocampal Memory Replay. Neuron 75, 700â€“713.\n",
    "\n",
    "It turns out, their baseline was actually the power over the entire epoch. This is also what the Frank lab recommended to Long Tao on the Slack channel as a baseline for comparison.\n",
    "\n",
    "So my first solution was to compute the Fourier transform over all time points in the epoch and match the frequency resolution. But this resulted in too many independent estimates in the frequency domain and trying to specify the right number of tapers to smooth this wasn't computationally feasible. In addition, I'd have way more frequency samples than the power/connectivity measure in the peri-ripple period.\n",
    "\n",
    "My second solution was to just use the same parameters as the ripple period and average the sliding window over the entire epoch (even if this introduces the windowing effect). This worked fine for power and coherence, but for group delay and pairwise spectral granger, this took a long time computationally and resulted in enormous files.\n",
    "\n",
    "So I have to find a way to speed up the spectral matrix decomposition for the spectral granger and the linear regression for the group delay or find an alternative solution. Most of time is taken up by the spectral matrix decomposition at ~9 minutes per iteration with a maximum of 30 iterations.\n",
    "\n",
    "### Computing connectivity over entire epoch\n",
    "We previously talked about examining the connectivity over the entire session, which I computed as part of the baseline, but I ran into the problems above (computational time and storage issues).\n",
    "\n",
    "### Wrote tutorial for Mehrnoosh explaining how to access the data\n",
    "I wrote a [tutorial](https://github.com/edeno/Jadhav-2016-Data-Analysis/blob/develop/notebooks/2017_06_23_Collecting_Data_On_Cluster.ipynb) that makes it easy to set up the same code environment that I'm using, including all the various software packages and dependencies. Also in this tutorial, I explain which functions in my code are useful for accessing information about the experiment, the spiking data, the position of the animals, etc.\n",
    "\n",
    "Mehrnoosh successfully forked my code repository and installed the code environment. She also now has access to the data in the Dropbox and I showed her where to put the data so that it would work with my code. The code for accessing the data now works after some minor debugging.\n",
    "\n",
    "### Fixed cluster issue where jobs were being killed for taking up more resources than requested.\n",
    "The cluster requires you to specify the number of cores for a given job on the cluster. If you take up more than the requested number of cores, your job is killed. Turns out the openBLAS library greedily uses as many cores as possible on a machine, so even if you specify a specific number of cores, say 12, if your job is run on a machine with 24 cores, it will use all 24 cores. The solution is to use an environmental variable to set the maximum number of threads openBLAS can use. Frustrating.\n",
    "\n",
    "### Started working on incorporating Long Tao's ripple detection method\n",
    "This is my general understanding of the algorithm, but I'm not quite getting all the details from his paper:\n",
    "\n",
    "So you have three sources of information:\n",
    "\n",
    "+  the hippocampal spiking\n",
    "+  the velocity of the animal\n",
    "+  and the multitaper ripple band power of the LFP\n",
    "\n",
    "You're calculating the likelihood of each of these and multiplying them together to combine the sources of information. The likelihoods are:\n",
    "\n",
    "+  The LFP power given the past LFP power and replay indicator\n",
    "+  the spiking given the past spiking and semi-latent state\n",
    "  +  the splines basis here is unclear. One splines basis is the semi-latent state and one spline basis I assume is over linear position?\n",
    "  +  the semi-latent state equals the animal's position when it's not in a replay state, is uniform when transitioning into the replay state, and has a sped up version during replay.\n",
    "+  the velocity given the past velocity, the replay indicator, and the semi-latent state\n",
    "\n",
    "You also have two(?) state transitions models:\n",
    "+  semi-latent state transition model\n",
    "+  replay indicator state transition model which is dependent on the past indicator and velocity\n",
    "      +  This is a logistic regression where the covariate is a spline basis of velocity over something? (don't know what M corresponds to).\n",
    "\n",
    "At each time step, you're calculating the posterior density of the replay state indicator and semi-latent state to get a one step prediction and then updating this prediction using the likelihood.\n",
    "\n",
    "### Testing collecting files on the cluster for plots\n",
    "Having tested collecting the data for one file and multiple files locally, I've tested the system on the cluster. After fixing an issue with the netCDF format, it works fine.\n",
    "\n",
    "\n",
    "### Connectivity measures now return xarray objects\n",
    "Previously my connectivity code returned numpy arrays (which are just like Matlab arrays). I was then externally converting these to xarray objects, which are convenient because they allow easy indexing, output to HDF5, plotting (see last week's report for more information). I started refactoring the code to return these by default, so I don't have to repeat the same code all the time.\n",
    "\n",
    "## Currently in progress\n",
    "\n",
    "Still working on producing the plots. The issues with the cluster (jobs were being killed, computing baseline over entire session taking too long and taking too much space) have slowed this down. I hope to at least show plots with the old baseline (-400 ms before ripple onset) by tomorrow morning, but I'm waiting for last cluster jobs to run tonight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Jadhav-2016-Data-Analysis]",
   "language": "python",
   "name": "conda-env-Jadhav-2016-Data-Analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
